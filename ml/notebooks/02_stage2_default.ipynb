{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0423df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    precision_recall_curve\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DATA_SAMPLE_DIR = Path(\"../data_sample\")\n",
    "ART_DIR = Path(\"../artifacts\")\n",
    "DATA_SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "ACCEPTED_CSV = DATA_DIR / \"accepted_2007_to_2018Q4.csv\"\n",
    "STAGE2_PARQUET = DATA_SAMPLE_DIR / \"stage2_sample.parquet\"\n",
    "\n",
    "MODEL_PATH = ART_DIR / \"stage2_pipeline.pkl\"\n",
    "METRICS_PATH = ART_DIR / \"stage2_metrics.json\"\n",
    "UI_META_PATH = ART_DIR / \"stage2_ui_metadata.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f72678d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "CANONICAL_COLS = [\n",
    "    \"loan_amount\",\n",
    "    \"term\",\n",
    "    \"purpose\",\n",
    "    \"annual_income\",\n",
    "    \"emp_length\",\n",
    "    \"dti\",\n",
    "    \"utilization\",\n",
    "    \"delinquencies\",\n",
    "    \"fico_est\",\n",
    "    \"fico_missing\",\n",
    "    \"emp_length_missing\",\n",
    "]\n",
    "TARGET = \"is_default\"  # Stage 2 label: 1=bad(default), 0=good(paid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4609cf5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_float(s: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def pct_to_float(s: pd.Series) -> pd.Series:\n",
    "    # handles \"55.2%\" or numeric\n",
    "    if s.dtype == \"O\":\n",
    "        s = s.astype(str).str.replace(\"%\", \"\", regex=False).str.strip()\n",
    "    return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "def clean_emp_length_fast(s: pd.Series) -> pd.Series:\n",
    "    if s.dtype != \"O\":\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "\n",
    "    st = s.astype(str).str.lower()\n",
    "    out = pd.Series(np.nan, index=s.index, dtype=\"float32\")\n",
    "\n",
    "    out[st.str.contains(r\"<\\s*1\", na=False)] = 0.5\n",
    "    out[st.str.contains(r\"10\\+\", na=False)] = 10.0\n",
    "\n",
    "    extracted = st.str.extract(r\"(\\d+)\", expand=False)\n",
    "    extracted_num = pd.to_numeric(extracted, errors=\"coerce\")\n",
    "\n",
    "    out = out.fillna(extracted_num)\n",
    "    return out.astype(\"float32\")\n",
    "\n",
    "def clip_fico(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.clip(lower=300, upper=850)\n",
    "\n",
    "def clip_nonneg(s: pd.Series) -> pd.Series:\n",
    "    s = pd.to_numeric(s, errors=\"coerce\")\n",
    "    return s.clip(lower=0)\n",
    "\n",
    "def parse_term_months(s: pd.Series) -> pd.Series:\n",
    "    if pd.api.types.is_numeric_dtype(s):\n",
    "        return pd.to_numeric(s, errors=\"coerce\")\n",
    "    #extract first number found\n",
    "    extracted = s.astype(str).str.extract(r\"(\\d+)\", expand=False)\n",
    "    return pd.to_numeric(extracted, errors=\"coerce\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642b9838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded accepted shape: (2260701, 11)\n",
      "Filtered to final-outcome loans: (1348099, 12)\n",
      "loan_status\n",
      "Fully Paid                                             1076751\n",
      "Charged Off                                             268559\n",
      "Does not meet the credit policy. Status:Fully Paid        1988\n",
      "Does not meet the credit policy. Status:Charged Off        761\n",
      "Default                                                     40\n",
      "Name: count, dtype: int64\n",
      "Default rate: 0.19980728418313493\n",
      "Stage2 canonical shape: (1348099, 12)\n",
      "Any NaNs left? False\n",
      "✅ Saved Stage 2 Parquet: ..\\data_sample\\stage2_sample.parquet\n",
      "term dtype: int64\n",
      "term NaN rate: 0.0\n",
      "term value counts:\n",
      "term\n",
      "36    1023206\n",
      "60     324893\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "USECOLS = [\n",
    "    \"loan_amnt\", \"term\", \"purpose\", \"annual_inc\", \"emp_length\", \"dti\",\n",
    "    \"revol_util\", \"delinq_2yrs\", \"fico_range_low\", \"fico_range_high\",\n",
    "    \"loan_status\"\n",
    "]\n",
    "\n",
    "acc = pd.read_csv(ACCEPTED_CSV, usecols=USECOLS, low_memory=False)\n",
    "print(\"Loaded accepted shape:\", acc.shape)\n",
    "\n",
    "#Build target\n",
    "good_status = {\n",
    "    \"Fully Paid\",\n",
    "    \"Does not meet the credit policy. Status:Fully Paid\"\n",
    "}\n",
    "bad_status = {\n",
    "    \"Charged Off\",\n",
    "    \"Default\",\n",
    "    \"Does not meet the credit policy. Status:Charged Off\"\n",
    "}\n",
    "\n",
    "acc = acc[acc[\"loan_status\"].isin(good_status | bad_status)].copy()\n",
    "acc[TARGET] = acc[\"loan_status\"].isin(bad_status).astype(\"int8\")\n",
    "\n",
    "print(\"Filtered to final-outcome loans:\", acc.shape)\n",
    "print(acc[\"loan_status\"].value_counts())\n",
    "print(\"Default rate:\", float(acc[TARGET].mean()))\n",
    "\n",
    "#Canonicalize features\n",
    "df2 = pd.DataFrame({\n",
    "    \"loan_amount\": to_float(acc[\"loan_amnt\"]),\n",
    "    \"term\": parse_term_months(acc[\"term\"]),  \n",
    "    \"purpose\": acc[\"purpose\"].astype(str),\n",
    "    \"annual_income\": to_float(acc[\"annual_inc\"]),\n",
    "    \"emp_length\": clean_emp_length_fast(acc[\"emp_length\"]),\n",
    "    \"dti\": pct_to_float(acc[\"dti\"]),\n",
    "    \"utilization\": pct_to_float(acc[\"revol_util\"]),\n",
    "    \"delinquencies\": to_float(acc[\"delinq_2yrs\"]),\n",
    "    \"fico_est\": (to_float(acc[\"fico_range_low\"]) + to_float(acc[\"fico_range_high\"])) / 2.0,\n",
    "    TARGET: acc[TARGET].astype(\"int8\")\n",
    "})\n",
    "\n",
    "#If term came in like \" 36 months\" fix it:\n",
    "if df2[\"term\"].dtype == \"O\":\n",
    "    df2[\"term\"] = pd.to_numeric(df2[\"term\"].astype(str).str.extract(r\"(\\d+)\", expand=False), errors=\"coerce\")\n",
    "\n",
    "df2[\"fico_est\"] = clip_fico(df2[\"fico_est\"])\n",
    "\n",
    "#Missingness flags BEFORE fill\n",
    "df2[\"fico_missing\"] = df2[\"fico_est\"].isna().astype(\"int8\")\n",
    "df2[\"emp_length_missing\"] = df2[\"emp_length\"].isna().astype(\"int8\")\n",
    "\n",
    "#Fill numeric with medians\n",
    "for col in [\"loan_amount\",\"term\",\"annual_income\",\"emp_length\",\"dti\",\"utilization\",\"delinquencies\",\"fico_est\"]:\n",
    "    med = float(pd.to_numeric(df2[col], errors=\"coerce\").median(skipna=True))\n",
    "    df2[col] = pd.to_numeric(df2[col], errors=\"coerce\").fillna(med)\n",
    "\n",
    "#Sanity clips to  remove outliers\n",
    "df2[\"loan_amount\"] = clip_nonneg(df2[\"loan_amount\"])\n",
    "df2[\"annual_income\"] = clip_nonneg(df2[\"annual_income\"])\n",
    "df2[\"delinquencies\"] = clip_nonneg(df2[\"delinquencies\"]).clip(upper=50)\n",
    "df2[\"dti\"] = df2[\"dti\"].clip(lower=0, upper=80)\n",
    "df2[\"utilization\"] = df2[\"utilization\"].clip(lower=0, upper=100)\n",
    "df2[\"emp_length\"] = df2[\"emp_length\"].clip(lower=0, upper=50)\n",
    "df2[\"term\"] = df2[\"term\"].clip(lower=0, upper=120)\n",
    "\n",
    "print(\"Stage2 canonical shape:\", df2.shape)\n",
    "print(\"Any NaNs left?\", df2.isna().any().any())\n",
    "\n",
    "#Save Parquet\n",
    "df2.to_parquet(STAGE2_PARQUET, index=False)\n",
    "print(\"✅ Saved Stage 2 Parquet:\", STAGE2_PARQUET)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "946bf87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1348099, 12)\n",
      "Default rate: 0.19980728418313493\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amount</th>\n",
       "      <th>term</th>\n",
       "      <th>purpose</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>dti</th>\n",
       "      <th>utilization</th>\n",
       "      <th>delinquencies</th>\n",
       "      <th>fico_est</th>\n",
       "      <th>is_default</th>\n",
       "      <th>fico_missing</th>\n",
       "      <th>emp_length_missing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3600.0</td>\n",
       "      <td>36</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>55000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>29.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>677.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24700.0</td>\n",
       "      <td>36</td>\n",
       "      <td>small_business</td>\n",
       "      <td>65000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.06</td>\n",
       "      <td>19.2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>717.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>60</td>\n",
       "      <td>home_improvement</td>\n",
       "      <td>63000.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>10.78</td>\n",
       "      <td>56.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10400.0</td>\n",
       "      <td>60</td>\n",
       "      <td>major_purchase</td>\n",
       "      <td>104433.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>25.37</td>\n",
       "      <td>64.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>697.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11950.0</td>\n",
       "      <td>36</td>\n",
       "      <td>debt_consolidation</td>\n",
       "      <td>34000.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.20</td>\n",
       "      <td>68.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan_amount  term             purpose  annual_income  emp_length    dti  utilization  delinquencies  fico_est  is_default  \\\n",
       "0       3600.0    36  debt_consolidation        55000.0        10.0   5.91         29.7            0.0     677.0           0   \n",
       "1      24700.0    36      small_business        65000.0        10.0  16.06         19.2            1.0     717.0           0   \n",
       "2      20000.0    60    home_improvement        63000.0        10.0  10.78         56.2            0.0     697.0           0   \n",
       "3      10400.0    60      major_purchase       104433.0         3.0  25.37         64.5            1.0     697.0           0   \n",
       "4      11950.0    36  debt_consolidation        34000.0         4.0  10.20         68.4            0.0     692.0           0   \n",
       "\n",
       "   fico_missing  emp_length_missing  \n",
       "0             0                   0  \n",
       "1             0                   0  \n",
       "2             0                   0  \n",
       "3             0                   0  \n",
       "4             0                   0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = pd.read_parquet(STAGE2_PARQUET)\n",
    "print(df2.shape)\n",
    "print(\"Default rate:\", float(df2[TARGET].mean()))\n",
    "df2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7a2a1f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numeric: ['loan_amount', 'term', 'annual_income', 'emp_length', 'dti', 'utilization', 'delinquencies', 'fico_est', 'fico_missing', 'emp_length_missing']\n",
      "Categorical: ['purpose']\n",
      "Train/Val/Test: (943669, 11) (202215, 11) (202215, 11)\n",
      "Train default rate: 0.19980734770348502\n"
     ]
    }
   ],
   "source": [
    "X = df2.drop(columns=[TARGET]).copy()\n",
    "y = df2[TARGET].astype(int).copy()\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "print(\"Numeric:\", num_cols)\n",
    "print(\"Categorical:\", cat_cols)\n",
    "\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train/Val/Test:\", X_train.shape, X_val.shape, X_test.shape)\n",
    "print(\"Train default rate:\", float(y_train.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d1b638de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\john_\\AppData\\Roaming\\Python\\Python314\\site-packages\\sklearn\\linear_model\\_logistic.py:1184: FutureWarning: 'n_jobs' has no effect since 1.8 and will be removed in 1.10. You provided 'n_jobs=-1', please leave it unspecified.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Val ROC-AUC: 0.678448382047025\n",
      "Val PR-AUC : 0.33953328641684877\n"
     ]
    }
   ],
   "source": [
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", categorical_pipe, cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "clf = LogisticRegression(\n",
    "    max_iter=800,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", clf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "val_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_proba)\n",
    "val_ap = average_precision_score(y_val, val_proba)\n",
    "\n",
    "print(\"Val ROC-AUC:\", val_auc)\n",
    "print(\"Val PR-AUC :\", val_ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8873e598",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold (val, max F1): 0.49945026156178474\n",
      "Best F1: 0.40469573629067956\n"
     ]
    }
   ],
   "source": [
    "prec, rec, thr = precision_recall_curve(y_val, val_proba)\n",
    "f1 = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "\n",
    "best_idx = int(np.argmax(f1))\n",
    "best_threshold = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n",
    "\n",
    "print(\"Best threshold (val, max F1):\", best_threshold)\n",
    "print(\"Best F1:\", float(f1[best_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd74fe1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ROC-AUC: 0.6795873126870401\n",
      "Test PR-AUC : 0.34120090585643514\n",
      "\n",
      "Confusion Matrix:\n",
      " [[105125  56686]\n",
      " [ 15926  24478]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8684    0.6497    0.7433    161811\n",
      "           1     0.3016    0.6058    0.4027     40404\n",
      "\n",
      "    accuracy                         0.6409    202215\n",
      "   macro avg     0.5850    0.6278    0.5730    202215\n",
      "weighted avg     0.7552    0.6409    0.6752    202215\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, test_proba)\n",
    "test_ap = average_precision_score(y_test, test_proba)\n",
    "\n",
    "test_pred = (test_proba >= best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "report = classification_report(y_test, test_pred, digits=4)\n",
    "\n",
    "print(\"Test ROC-AUC:\", test_auc)\n",
    "print(\"Test PR-AUC :\", test_ap)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537e52f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Val ROC-AUC: 0.6874405278446104\n",
      "GB Val PR-AUC : 0.3514251478699275\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "\n",
    "gb = HistGradientBoostingClassifier(\n",
    "    learning_rate=0.05,\n",
    "    max_depth=6,\n",
    "    max_iter=300,\n",
    "    random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "gb_pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", gb)\n",
    "])\n",
    "\n",
    "gb_pipe.fit(X_train, y_train)\n",
    "\n",
    "val_proba_gb = gb_pipe.predict_proba(X_val)[:, 1]\n",
    "val_auc_gb = roc_auc_score(y_val, val_proba_gb)\n",
    "val_ap_gb = average_precision_score(y_val, val_proba_gb)\n",
    "\n",
    "print(\"GB Val ROC-AUC:\", val_auc_gb)\n",
    "print(\"GB Val PR-AUC :\", val_ap_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65bf002c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GB Test ROC-AUC: 0.6887419428230931\n",
      "GB Test PR-AUC : 0.3525630074473265\n"
     ]
    }
   ],
   "source": [
    "test_proba_gb = gb_pipe.predict_proba(X_test)[:, 1]\n",
    "test_auc_gb = roc_auc_score(y_test, test_proba_gb)\n",
    "test_ap_gb = average_precision_score(y_test, test_proba_gb)\n",
    "\n",
    "print(\"GB Test ROC-AUC:\", test_auc_gb)\n",
    "print(\"GB Test PR-AUC :\", test_ap_gb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ddd2acd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen threshold: 0.4465711966985147\n",
      "Note: Chosen to meet precision >= 0.5 with max recall.\n",
      "Val precision @ threshold: 0.5\n",
      "Val recall    @ threshold: 0.08375408375408376\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "target_precision = 0.50  #favor precision\n",
    "\n",
    "prec, rec, thr = precision_recall_curve(y_val, val_proba_gb)\n",
    "\n",
    "valid = np.where(prec[:-1] >= target_precision)[0]\n",
    "\n",
    "if len(valid) == 0:\n",
    "    best_idx = int(np.argmax(prec[:-1]))\n",
    "    chosen_threshold = float(thr[best_idx])\n",
    "    chosen_note = f\"Target precision {target_precision} not reachable; using max precision point.\"\n",
    "else:\n",
    "    best_idx = valid[np.argmax(rec[:-1][valid])]\n",
    "    chosen_threshold = float(thr[best_idx])\n",
    "    chosen_note = f\"Chosen to meet precision >= {target_precision} with max recall.\"\n",
    "\n",
    "print(\"Chosen threshold:\", chosen_threshold)\n",
    "print(\"Note:\", chosen_note)\n",
    "print(\"Val precision @ threshold:\", float(prec[best_idx]))\n",
    "print(\"Val recall    @ threshold:\", float(rec[best_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd1562ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[158428   3383]\n",
      " [ 37022   3382]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8106    0.9791    0.8869    161811\n",
      "           1     0.4999    0.0837    0.1434     40404\n",
      "\n",
      "    accuracy                         0.8002    202215\n",
      "   macro avg     0.6553    0.5314    0.5152    202215\n",
      "weighted avg     0.7485    0.8002    0.7383    202215\n",
      "\n",
      "\n",
      "Operational metrics (test):\n",
      "Precision (bad=1): 0.4999\n",
      "Recall (bad=1):    0.0837\n",
      "F1 (bad=1):        0.1434\n",
      "FPR:               0.0209\n",
      "Flag rate (pred=1):0.0335\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "test_pred = (test_proba_gb >= chosen_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "\n",
    "precision = tp / (tp + fp + 1e-12)\n",
    "recall = tp / (tp + fn + 1e-12)\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-12)\n",
    "fpr = fp / (fp + tn + 1e-12)\n",
    "pass_rate = (tp + fp) / (tp + fp + tn + fn)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, test_pred, digits=4))\n",
    "\n",
    "print(\"\\nOperational metrics (test):\")\n",
    "print(f\"Precision (bad=1): {precision:.4f}\")\n",
    "print(f\"Recall (bad=1):    {recall:.4f}\")\n",
    "print(f\"F1 (bad=1):        {f1:.4f}\")\n",
    "print(f\"FPR:               {fpr:.4f}\")\n",
    "print(f\"Flag rate (pred=1):{pass_rate:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "176b8a12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HIGH threshold: 0.4465711966985147 | val precision: 0.5 | val recall: 0.08375408375408376 | min_precision_max_recall\n",
      "MED  threshold: 0.2560286357072218 | val precision: 0.3500009720629119 | val recall: 0.4455746955746956 | min_precision_max_recall\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def threshold_for_min_precision(y_true, proba, target_precision: float):\n",
    "    prec, rec, thr = precision_recall_curve(y_true, proba)\n",
    "    valid = np.where(prec[:-1] >= target_precision)[0]\n",
    "    if len(valid) == 0:\n",
    "        best_idx = int(np.argmax(prec[:-1]))\n",
    "        return float(thr[best_idx]), float(prec[best_idx]), float(rec[best_idx]), \"max_precision_fallback\"\n",
    "    best_idx = valid[np.argmax(rec[:-1][valid])]\n",
    "    return float(thr[best_idx]), float(prec[best_idx]), float(rec[best_idx]), \"min_precision_max_recall\"\n",
    "\n",
    "t_high, p_high, r_high, rule_high = threshold_for_min_precision(y_val, val_proba_gb, 0.50)\n",
    "t_med,  p_med,  r_med,  rule_med  = threshold_for_min_precision(y_val, val_proba_gb, 0.35)\n",
    "\n",
    "print(\"HIGH threshold:\", t_high, \"| val precision:\", p_high, \"| val recall:\", r_high, \"|\", rule_high)\n",
    "print(\"MED  threshold:\", t_med,  \"| val precision:\", p_med,  \"| val recall:\", r_med,  \"|\", rule_med)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3373898a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low       0.745073\n",
      "Medium    0.221472\n",
      "High      0.033454\n",
      "Name: proportion, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "band\n",
       "High      0.499926\n",
       "Low       0.147931\n",
       "Medium    0.328994\n",
       "Name: y, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def risk_band(proba, t_med, t_high):\n",
    "    if proba >= t_high:\n",
    "        return \"High\"\n",
    "    elif proba >= t_med:\n",
    "        return \"Medium\"\n",
    "    else:\n",
    "        return \"Low\"\n",
    "\n",
    "bands = pd.Series([risk_band(p, t_med, t_high) for p in test_proba_gb])\n",
    "print(bands.value_counts(normalize=True))\n",
    "\n",
    "# Check actual default rates by band (this is VERY compelling for your UI + writeup)\n",
    "band_df = pd.DataFrame({\"band\": bands, \"y\": y_test.values})\n",
    "display(band_df.groupby(\"band\")[\"y\"].mean().sort_index())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b2c9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model: ..\\artifacts\\stage2_pipeline.pkl\n",
      "Saved metrics: ..\\artifacts\\stage2_metrics.json\n",
      "Saved UI metadata: ..\\artifacts\\stage2_ui_metadata.json\n",
      "\n",
      "Thresholds:\n",
      "t_med : 0.2560286357072218 | val precision: 0.3500009720629119 | val recall: 0.4455746955746956\n",
      "t_high: 0.4465711966985147 | val precision: 0.5 | val recall: 0.08375408375408376\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(pipe, MODEL_PATH)\n",
    "print(\"Saved model:\", MODEL_PATH)\n",
    "\n",
    "metrics = {\n",
    "    \"stage\": \"stage2_default_risk\",\n",
    "    \"model\": \"hist_gradient_boosting\",\n",
    "    \"target_definition\": {\n",
    "        \"good\": [\"Fully Paid\", \"Does not meet the credit policy. Status:Fully Paid\"],\n",
    "        \"bad\": [\"Charged Off\", \"Default\", \"Does not meet the credit policy. Status:Charged Off\"],\n",
    "        \"dropped\": [\"Current\", \"Late (16-30 days)\", \"Late (31-120 days)\", \"In Grace Period\"]\n",
    "    },\n",
    "    \"features\": X.columns.tolist(),\n",
    "    \"val_roc_auc\": float(val_auc),\n",
    "    \"val_pr_auc\": float(val_ap),\n",
    "    \"test_roc_auc\": float(test_auc),\n",
    "    \"test_pr_auc\": float(test_ap),\n",
    "\n",
    "    \"threshold\": float(t_high),\n",
    "\n",
    "    \"band_policy\": {\n",
    "        \"risk_bands\": {\n",
    "            \"low\":    {\"max\": float(t_med)},\n",
    "            \"medium\": {\"min\": float(t_med), \"max\": float(t_high)},\n",
    "            \"high\":   {\"min\": float(t_high)}\n",
    "        },\n",
    "        \"how_chosen\": {\n",
    "            \"t_high\": {\"min_precision\": 0.50, \"val_precision\": float(p_high), \"val_recall\": float(r_high), \"rule\": rule_high},\n",
    "            \"t_med\":  {\"min_precision\": 0.35, \"val_precision\": float(p_med),  \"val_recall\": float(r_med),  \"rule\": rule_med}\n",
    "        }\n",
    "    },\n",
    "\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "    \"classification_report\": report\n",
    "}\n",
    "\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved metrics:\", METRICS_PATH)\n",
    "\n",
    "def make_numeric_metadata(df_train: pd.DataFrame, columns: list[str]) -> dict:\n",
    "    meta = {}\n",
    "    for c in columns:\n",
    "        s = pd.to_numeric(df_train[c], errors=\"coerce\").dropna()\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        meta[c] = {\n",
    "            \"min\": float(s.min()),\n",
    "            \"max\": float(s.max()),\n",
    "            \"p1\": float(np.percentile(s, 1)),\n",
    "            \"p99\": float(np.percentile(s, 99)),\n",
    "            \"recommended_min\": float(np.percentile(s, 10)),\n",
    "            \"recommended_max\": float(np.percentile(s, 90)),\n",
    "        }\n",
    "    return meta\n",
    "\n",
    "ui_meta = {\n",
    "    \"stage\": \"stage2_default_risk\",\n",
    "    \"numeric\": make_numeric_metadata(X_train, num_cols),\n",
    "    \"categorical\": {\n",
    "        c: X_train[c].astype(str).value_counts().head(30).index.tolist()\n",
    "        for c in cat_cols\n",
    "    }\n",
    "}\n",
    "\n",
    "with open(UI_META_PATH, \"w\") as f:\n",
    "    json.dump(ui_meta, f, indent=2)\n",
    "\n",
    "print(\"Saved UI metadata:\", UI_META_PATH)\n",
    "\n",
    "print(\"\\nThresholds:\")\n",
    "print(\"t_med :\", t_med,  \"| val precision:\", p_med,  \"| val recall:\", r_med)\n",
    "print(\"t_high:\", t_high, \"| val precision:\", p_high, \"| val recall:\", r_high)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
