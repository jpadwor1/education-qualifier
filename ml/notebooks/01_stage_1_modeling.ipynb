{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecbc172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import joblib\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import (\n",
    "    roc_auc_score, average_precision_score,\n",
    "    classification_report, confusion_matrix,\n",
    "    precision_recall_curve, roc_curve\n",
    ")\n",
    "\n",
    "pd.set_option(\"display.max_columns\", 200)\n",
    "pd.set_option(\"display.width\", 140)\n",
    "\n",
    "RANDOM_STATE = 123\n",
    "\n",
    "DATA_SAMPLE_DIR = Path(\"../data_sample\")\n",
    "ART_DIR = Path(\"../artifacts\")\n",
    "ART_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SAMPLE_PATH = DATA_SAMPLE_DIR / \"stage1_sample.parquet\"\n",
    "\n",
    "MODEL_PATH = ART_DIR / \"stage1_pipeline.pkl\"\n",
    "METRICS_PATH = ART_DIR / \"stage1_metrics.json\"\n",
    "UI_META_PATH = ART_DIR / \"stage1_ui_metadata.json\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94396999",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(SAMPLE_PATH)\n",
    "\n",
    "print(\"Shape:\", df.shape)\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "print(\"\\nLabel distribution:\")\n",
    "print(df[\"is_accepted\"].value_counts(normalize=True))\n",
    "\n",
    "display(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cba043df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Missingness check\n",
    "missing = df.isna().mean().sort_values(ascending=False)\n",
    "print(\"Top missingness should be ~0:\")\n",
    "display(missing.head(10))\n",
    "\n",
    "#Quick descriptive stats\n",
    "display(df.describe().T)\n",
    "\n",
    "#Flag sanity missingness flags should be 0/1\n",
    "print(\"\\nFlag rates by class:\")\n",
    "display(df.groupby(\"is_accepted\")[[\"fico_missing\", \"emp_length_missing\"]].mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d157ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"is_accepted\"\n",
    "\n",
    "X = df.drop(columns=[TARGET]).copy()\n",
    "y = df[TARGET].astype(int).copy()\n",
    "\n",
    "num_cols = X.select_dtypes(include=[\"number\", \"bool\"]).columns.tolist()\n",
    "cat_cols = [c for c in X.columns if c not in num_cols]\n",
    "\n",
    "print(\"Numeric cols:\", num_cols)\n",
    "print(\"Categorical cols:\", cat_cols) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23104581",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "    X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y\n",
    ")\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.50, random_state=RANDOM_STATE, stratify=y_temp\n",
    ")\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "print(\"Train pos rate:\", float(y_train.mean()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6caa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_pipe = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()) \n",
    "])\n",
    "\n",
    "preprocess = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_pipe, num_cols),\n",
    "        (\"cat\", Pipeline(steps=[\n",
    "            (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "            (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "        ]), cat_cols),\n",
    "    ],\n",
    "    remainder=\"drop\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780e878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LogisticRegression(\n",
    "    max_iter=500,\n",
    "    class_weight=\"balanced\",\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "pipe = Pipeline(steps=[\n",
    "    (\"prep\", preprocess),\n",
    "    (\"model\", clf)\n",
    "])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "\n",
    "val_proba = pipe.predict_proba(X_val)[:, 1]\n",
    "val_auc = roc_auc_score(y_val, val_proba)\n",
    "val_ap = average_precision_score(y_val, val_proba)\n",
    "\n",
    "print(\"Validation ROC-AUC:\", val_auc)\n",
    "print(\"Validation PR-AUC :\", val_ap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce828b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "prec, rec, thr = precision_recall_curve(y_val, val_proba)\n",
    "f1 = (2 * prec * rec) / (prec + rec + 1e-12)\n",
    "\n",
    "best_idx = np.argmax(f1)\n",
    "best_threshold = float(thr[best_idx]) if best_idx < len(thr) else 0.5\n",
    "\n",
    "print(\"Best threshold (val, max F1):\", best_threshold)\n",
    "print(\"Best F1:\", float(f1[best_idx]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813bcb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_proba = pipe.predict_proba(X_test)[:, 1]\n",
    "test_auc = roc_auc_score(y_test, test_proba)\n",
    "test_ap = average_precision_score(y_test, test_proba)\n",
    "\n",
    "test_pred = (test_proba >= best_threshold).astype(int)\n",
    "\n",
    "cm = confusion_matrix(y_test, test_pred)\n",
    "report = classification_report(y_test, test_pred, digits=4)\n",
    "\n",
    "print(\"Test ROC-AUC:\", test_auc)\n",
    "print(\"Test PR-AUC :\", test_ap)\n",
    "print(\"\\nConfusion Matrix:\\n\", cm)\n",
    "print(\"\\nClassification Report:\\n\", report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8834cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "joblib.dump(pipe, MODEL_PATH)\n",
    "print(\"Saved model:\", MODEL_PATH)\n",
    "\n",
    "metrics = {\n",
    "    \"stage\": \"stage1_acceptance\",\n",
    "    \"model\": \"logistic_regression\",\n",
    "    \"features\": X.columns.tolist(),\n",
    "    \"num_cols\": num_cols,\n",
    "    \"cat_cols\": cat_cols,\n",
    "    \"val_roc_auc\": float(val_auc),\n",
    "    \"val_pr_auc\": float(val_ap),\n",
    "    \"test_roc_auc\": float(test_auc),\n",
    "    \"test_pr_auc\": float(test_ap),\n",
    "    \"threshold\": float(best_threshold),\n",
    "    \"confusion_matrix\": cm.tolist(),\n",
    "    \"classification_report\": report\n",
    "}\n",
    "\n",
    "with open(METRICS_PATH, \"w\") as f:\n",
    "    json.dump(metrics, f, indent=2)\n",
    "\n",
    "print(\"Saved metrics:\", METRICS_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46bf6e96",
   "metadata": {},
   "source": [
    "Create the metadata to use on the frontend "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea89b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_numeric_metadata(df_train: pd.DataFrame, columns: list[str]) -> dict:\n",
    "    meta = {}\n",
    "    for c in columns:\n",
    "        s = pd.to_numeric(df_train[c], errors=\"coerce\").dropna()\n",
    "        if len(s) == 0:\n",
    "            continue\n",
    "        meta[c] = {\n",
    "            \"min\": float(s.min()),\n",
    "            \"max\": float(s.max()),\n",
    "            \"p1\": float(np.percentile(s, 1)),\n",
    "            \"p99\": float(np.percentile(s, 99)),\n",
    "            \"recommended_min\": float(np.percentile(s, 10)),\n",
    "            \"recommended_max\": float(np.percentile(s, 90)),\n",
    "        }\n",
    "    return meta\n",
    "\n",
    "ui_meta = {\n",
    "    \"stage\": \"stage1_acceptance\",\n",
    "    \"numeric\": make_numeric_metadata(X_train, num_cols),\n",
    "    \"categorical\": {}  # none expected in Stage 1\n",
    "}\n",
    "\n",
    "with open(UI_META_PATH, \"w\") as f:\n",
    "    json.dump(ui_meta, f, indent=2)\n",
    "\n",
    "print(\"Saved UI metadata:\", UI_META_PATH)\n",
    "ui_meta\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
